# -*- coding: utf-8 -*-
"""FeatureEngieering.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lBfF1ZxlGAlA_wh0oB2FhcqItk5hpTEN

### 1. **What is a parameter?**

A **parameter** is an internal variable of a model that is learned from the training data.
For example, in linear regression, the **slope (m)** and **intercept (b)** in the equation `y = mx + b` are parameters.

---

### 2. **What is correlation?**

**Correlation** measures the statistical relationship between two variables, showing how closely they move together.
It ranges from **-1 to 1**:

* `+1`: Perfect positive correlation
* `0`: No correlation
* `-1`: Perfect negative correlation

---

### 3. **What does negative correlation mean?**

A **negative correlation** means that as one variable **increases**, the other **decreases**.
Example: Increase in exercise time leads to a **decrease in body fat percentage**.

---

### 4. **Define Machine Learning. What are the main components in Machine Learning?**

**Machine Learning (ML)** is a subset of AI that allows systems to learn patterns from data and make decisions or predictions.

**Main components**:

* **Data**
* **Features**
* **Model**
* **Loss function**
* **Optimizer**
* **Evaluation metrics**

---

### 5. **How does loss value help in determining whether the model is good or not?**

The **loss value** represents how far the predicted outputs are from the actual values.

* **Low loss** = Good model
* **High loss** = Poor model
  The goal of training is to **minimize the loss**.

---

### 6. **What are continuous and categorical variables?**

* **Continuous variables**: Numeric values with infinite possibilities (e.g., height, weight).
* **Categorical variables**: Values that represent categories (e.g., gender, color, city).

---

### 7. **How do we handle categorical variables in Machine Learning? What are the common techniques?**

**Techniques to handle categorical data**:

* **Label Encoding** – Converts categories into numbers.
* **One-Hot Encoding** – Creates binary columns for each category.
* **Ordinal Encoding** – Useful when categories have a natural order.

---

### 8. **What do you mean by training and testing a dataset?**

* **Training set**: Used to teach the model (fit the model).
* **Testing set**: Used to evaluate the model’s performance on unseen data.

---

### 9. **What is `sklearn.preprocessing`?**

`sklearn.preprocessing` is a module in scikit-learn for:

* Scaling
* Normalization
* Encoding categorical features
* Imputing missing values
  Example:

```python
from sklearn.preprocessing import StandardScaler, OneHotEncoder
```

---

### 10. **What is a Test set?**

The **test set** is a portion of the dataset reserved to **evaluate model performance** after training.
It checks how well the model generalizes to **unseen data**.

---

### 11. **How do we split data for model fitting (training and testing) in Python?**

Using `train_test_split()` from scikit-learn:

```python
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
```

---

### 12. **How do you approach a Machine Learning problem?**

* Understand the **problem** and **goal**
* Perform **EDA (Exploratory Data Analysis)**
* Handle **missing values** and **outliers**
* Encode **categorical data**
* Scale/normalize features
* Split data (train/test)
* Choose and train a **model**
* Evaluate using metrics (accuracy, RMSE, etc.)
* Optimize and retrain if needed

---

### 13. **Why do we have to perform EDA before fitting a model to the data?**

**EDA (Exploratory Data Analysis)** helps in:

* Understanding data patterns
* Identifying missing values and outliers
* Choosing the right preprocessing steps
* Selecting relevant features

---

### 14. **How can you find correlation between variables in Python?**

```python
import pandas as pd
df = pd.read_csv("data.csv")
correlation_matrix = df.corr()
```

---

### 15. **What is causation? Explain difference between correlation and causation with an example.**

* **Causation**: One variable **causes** the change in another.
* **Correlation**: Two variables move together, but **not necessarily due to cause-effect**.

**Example**:

* Ice cream sales ↑ and drowning cases ↑ = Correlation
* But cause = High temperature, not ice cream

---

### 16. **What is an Optimizer? What are different types of optimizers?**

An **optimizer** adjusts the model’s parameters to reduce the loss.

**Common optimizers**:

* **SGD** (Stochastic Gradient Descent)
* **Adam** (Adaptive Moment Estimation)
* **RMSprop**

**Example**:

```python
optimizer = tf.keras.optimizers.Adam()
```

---

### 17. **What is `sklearn.linear_model`?**

A module in scikit-learn that provides linear models like:

* **LinearRegression**
* **LogisticRegression**
* **Ridge**, **Lasso**, etc.

**Example**:

```python
from sklearn.linear_model import LinearRegression
model = LinearRegression()
```

---

### 18. **What does `model.fit()` do? What arguments must be given?**

* `model.fit(X, y)` trains the model using features `X` and target `y`.

---

### 19. **What does `model.predict()` do? What arguments must be given?**

* `model.predict(X_test)` uses the trained model to **predict outcomes** for `X_test`.

---

### 20. **What is feature scaling? How does it help in Machine Learning?**

**Feature scaling** standardizes the range of features to improve model performance and training speed.
It’s crucial for algorithms like:

* KNN
* SVM
* Gradient descent

---

### 21. **How do we perform scaling in Python?**

Using **StandardScaler** or **MinMaxScaler**:

```python
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
```

---

### 22. **Explain data encoding**

**Data encoding** converts categorical variables into numeric format so ML models can process them.

**Common types**:

* Label Encoding
* One-Hot Encoding
* Ordinal Encoding

**Example:**

```python
from sklearn.preprocessing import OneHotEncoder
```
"""