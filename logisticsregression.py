# -*- coding: utf-8 -*-
"""LogisticsRegression.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lBfF1ZxlGAlA_wh0oB2FhcqItk5hpTEN

**. What is Logistic Regression, and how does it differ from Linear Regression?**
Logistic Regression is a classification algorithm used to predict binary outcomes, modeling the probability of a class using the logistic (sigmoid) function. Linear Regression predicts continuous numeric values, while Logistic Regression predicts probabilities mapped between 0 and 1.

---

**. What is the mathematical equation of Logistic Regression?**
The logistic regression model predicts probability $p$ as:
$p = \frac{1}{1 + e^{-(\beta_0 + \beta_1 x_1 + \dots + \beta_n x_n)}}$

---

**. Why do we use the Sigmoid function in Logistic Regression?**
The sigmoid function maps any real-valued number into the (0, 1) range, allowing the output to be interpreted as a probability for classification.

---

**. What is the cost function of Logistic Regression?**
The cost function is the **log loss** or **binary cross-entropy**:

$$
J(\theta) = -\frac{1}{m} \sum_{i=1}^m \left[y^{(i)} \log(h_\theta(x^{(i)})) + (1 - y^{(i)}) \log(1 - h_\theta(x^{(i)}))\right]
$$

---

**. What is Regularization in Logistic Regression? Why is it needed?**
Regularization adds a penalty term to the loss function to prevent overfitting by constraining the size of coefficients, improving generalization.

---

**"C. Explain the difference between Lasso, Ridge, and Elastic Net regression**

* **Lasso (L1):** Adds sum of absolute values of coefficients, promotes sparsity (feature selection).
* **Ridge (L2):** Adds sum of squares of coefficients, shrinks coefficients but keeps all features.
* **Elastic Net:** Combines L1 and L2 penalties, balancing sparsity and coefficient shrinkage.

---

*. When should we use Elastic Net instead of Lasso or Ridge?**
Use Elastic Net when you have many correlated features or want both feature selection and coefficient shrinkage.

---

**. What is the impact of the regularization parameter (Î») in Logistic Regression?**
Higher $\lambda$ increases penalty strength, shrinking coefficients more and reducing overfitting; too high $\lambda$ can underfit.

---

*. What are the key assumptions of Logistic Regression?**

* The outcome is binary.
* Observations are independent.
* No perfect multicollinearity among predictors.
* Linear relationship between log-odds and predictors.

---

**. What are some alternatives to Logistic Regression for classification tasks?**
Decision Trees, Random Forest, Support Vector Machines (SVM), k-Nearest Neighbors (kNN), Neural Networks.

---

**. What are Classification Evaluation Metrics?**
Accuracy, Precision, Recall, F1-score, ROC-AUC, Confusion Matrix.

---

**. How does class imbalance affect Logistic Regression?**
Class imbalance can bias the model toward the majority class, reducing performance on minority class detection.

---

**. What is Hyperparameter Tuning in Logistic Regression?**
Process of selecting optimal parameters (like regularization strength and solver) to improve model performance.

---

**. What are different solvers in Logistic Regression? Which one should be used?**
Common solvers: `liblinear`, `newton-cg`, `lbfgs`, `sag`, `saga`.

* Use `liblinear` for small datasets or L1 penalty, `lbfgs` or `newton-cg` for larger datasets and L2 penalty.

---

**. How is Logistic Regression extended for multiclass classification?**
Using strategies like One-vs-Rest (OvR) or Softmax (multinomial logistic regression).

---

**. What are the advantages and disadvantages of Logistic Regression?**

* Advantages: Simple, interpretable, efficient, outputs probabilities.
* Disadvantages: Assumes linearity in log-odds, limited for complex patterns.

---

**. What are some use cases of Logistic Regression?**
Spam detection, medical diagnosis (disease presence), credit scoring, customer churn prediction.

---

**. What is the difference between Softmax Regression and Logistic Regression?**
Softmax regression generalizes logistic regression to multiple (>2) classes by producing probabilities for each class.

---

**. How do we choose between One-vs-Rest (OvR) and Softmax for multiclass classification?**
OvR is simpler and works well for many classes; Softmax is preferred for mutually exclusive classes and when class probabilities are needed.

---

**'. How do we interpret coefficients in Logistic Regression?**
Coefficients represent the change in the log-odds of the outcome per unit increase in the predictor; exponentiating coefficients gives odds ratios.
"""